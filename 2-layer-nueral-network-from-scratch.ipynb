{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:51:12.802149Z","iopub.execute_input":"2025-05-14T19:51:12.802489Z","iopub.status.idle":"2025-05-14T19:51:12.807232Z","shell.execute_reply.started":"2025-05-14T19:51:12.802463Z","shell.execute_reply":"2025-05-14T19:51:12.806351Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:51:12.821192Z","iopub.execute_input":"2025-05-14T19:51:12.822117Z","iopub.status.idle":"2025-05-14T19:51:15.189932Z","shell.execute_reply.started":"2025-05-14T19:51:12.822086Z","shell.execute_reply":"2025-05-14T19:51:15.189006Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:51:15.191757Z","iopub.execute_input":"2025-05-14T19:51:15.192134Z","iopub.status.idle":"2025-05-14T19:51:15.207985Z","shell.execute_reply.started":"2025-05-14T19:51:15.192102Z","shell.execute_reply":"2025-05-14T19:51:15.206945Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"data = np.array(data)\nm,n = data.shape\nprint(m,n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:51:15.208859Z","iopub.execute_input":"2025-05-14T19:51:15.209173Z","iopub.status.idle":"2025-05-14T19:51:15.351521Z","shell.execute_reply.started":"2025-05-14T19:51:15.209143Z","shell.execute_reply":"2025-05-14T19:51:15.350458Z"}},"outputs":[{"name":"stdout","text":"42000 785\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"np.random.shuffle(data)\ndata_dev = data[0:1000].T\ny_dev = data_dev[0] #selecting the first row which contains labels of each training samples\nx_dev = data_dev[1:n] /255.0\ndata_train = data[1000:m].T\ny_train = data_train[0]\nx_train = data_train[1:n] /255.0\nprint(y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:51:15.353680Z","iopub.execute_input":"2025-05-14T19:51:15.354046Z","iopub.status.idle":"2025-05-14T19:51:16.061455Z","shell.execute_reply.started":"2025-05-14T19:51:15.354016Z","shell.execute_reply":"2025-05-14T19:51:16.060565Z"}},"outputs":[{"name":"stdout","text":"[5 4 3 ... 3 7 8]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(x_train[:, 0].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:51:16.062460Z","iopub.execute_input":"2025-05-14T19:51:16.062776Z","iopub.status.idle":"2025-05-14T19:51:16.068374Z","shell.execute_reply.started":"2025-05-14T19:51:16.062745Z","shell.execute_reply":"2025-05-14T19:51:16.067315Z"}},"outputs":[{"name":"stdout","text":"(784,)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def init_parameters():\n    W1 = np.random.randn(16, 784) * 0.01 \n    b1 = np.zeros((16, 1))\n    W2 = np.random.randn(16, 16) * 0.01\n    b2 = np.zeros((16, 1))\n    W3 = np.random.randn(10, 16) * 0.01\n    b3 = np.zeros((10, 1))\n    \n    return {\n        \"W1\" : W1, \n        \"W2\" : W2,\n        \"W3\" : W3, \n        \"b1\" : b1, \n        \"b2\" : b2, \n        \"b3\" : b3\n    }\n\ndef ReLu(z):\n    return np.maximum(0,z)\n\ndef SoftMax(z):\n    z_shifted = z - np.max(z, axis = 0, keepdims = True)\n    z_exp = np.exp(z_shifted) #shifted to prevent overflow \n    exponential_sum = np.sum (z_exp, axis = 0, keepdims = True)\n    return z_exp / exponential_sum # returns an array of probablistic distributions\n    \n\ndef forward_propagation(X, parameters):\n    Z1 = parameters[\"W1\"].dot(X) + parameters[\"b1\"]\n    a1 = ReLu(Z1) \n    Z2 = parameters[\"W2\"].dot(a1) + parameters[\"b2\"]\n    a2 = ReLu(Z2) \n    Z3 = parameters[\"W3\"].dot(a2) + parameters[\"b3\"]\n    a3 = SoftMax(Z3) \n    \n    return Z1, a1, Z2, a2, Z3, a3\n\ndef one_hot_encoding(Y):\n    Y_encoded = np.zeros((Y.size, 10))\n    Y_encoded[np.arange(Y.size), Y] = 1\n    return Y_encoded.T\n\ndef calculate_loss(a3, y):\n    #using cross entropy loss fn here \n    epsilon = 1e-12\n    #predicted probablities are clipped between 0 and 1 to avoid crashes ( log(0) =1 , log(1) = 0)\n    a3_clipped = np.clip(a3, epsilon, 1-epsilon)\n    loss = -np.sum(y * np.log(a3_clipped))/y.shape[1]\n    return loss\n\n    \ndef backward_propagation(X, Y_hot_encoded, parameters, Z1, a1, Z2, a2, Z3, a3, m):\n    dZ3 = a3 - Y_hot_encoded\n    dZ2 = parameters[\"W3\"].T.dot(dZ3) * (Z2 > 0)\n    dZ1 = parameters[\"W2\"].T.dot(dZ2) * (Z1 > 0)\n\n    dW3 = dZ3.dot(a2.T) / m\n    dW2 = dZ2.dot(a1.T) / m\n    dW1 = dZ1.dot(X.T) / m\n\n    db3 = np.sum(dZ3, axis = 1 , keepdims = True) / m\n    db2 = np.sum(dZ2, axis = 1 , keepdims = True) / m\n    db1 = np.sum(dZ1, axis = 1 , keepdims = True) / m\n\n    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2, \"dW3\": dW3, \"db3\": db3}\n\ndef gradient_descent(gradients, parameters, lr):\n        parameters[\"W3\"] -= lr * gradients[\"dW3\"]\n        parameters[\"b3\"] -= lr * gradients[\"db3\"]\n        parameters[\"W2\"] -= lr * gradients[\"dW2\"]\n        parameters[\"b2\"] -= lr * gradients[\"db2\"]\n        parameters[\"W1\"] -= lr * gradients[\"dW1\"]\n        parameters[\"b1\"] -= lr * gradients[\"db1\"]\n        return parameters\n\ndef train(X_train, Y_train, learning_rate=0.01, epochs=1000, batch_size=64):\n    parameters = init_parameters()\n    for epoch in range(epochs):\n        permutation = np.random.permutation(X_train.shape[1])\n        X_shuffled = X_train[:, permutation]\n        Y_shuffled = Y_train[permutation]\n        for i in range(0, X_train.shape[1], batch_size):\n            X_batch = X_shuffled[:, i:i+batch_size]\n            Y_batch = Y_shuffled[i:i+batch_size]\n            Z1, A1, Z2, A2, Z3, A3 = forward_propagation(X_batch, parameters)\n            Y_one_hot = one_hot_encoding(Y_batch)\n            loss = calculate_loss(A3, Y_one_hot)\n            gradients = backward_propagation(X_batch, Y_one_hot, parameters, Z1, A1, Z2, A2, Z3, A3, batch_size)\n            parameters = gradient_descent(gradients, parameters, learning_rate)\n        if epoch % 100 == 0:\n            print(f\"Epoch {epoch}, Loss: {loss}\")\n    return parameters\n\ntrained_params = train(x_train, y_train, learning_rate=0.1, epochs=1000, batch_size=64)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T19:59:37.574386Z","iopub.execute_input":"2025-05-14T19:59:37.574758Z","iopub.status.idle":"2025-05-14T20:10:07.614354Z","shell.execute_reply.started":"2025-05-14T19:59:37.574733Z","shell.execute_reply":"2025-05-14T20:10:07.613276Z"}},"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 2.0534368399693155\nEpoch 100, Loss: 0.05409087222982386\nEpoch 200, Loss: 0.017993214471590042\nEpoch 300, Loss: 0.0002927940837006458\nEpoch 400, Loss: 4.973635705660889e-06\nEpoch 500, Loss: 1.4780886008207606e-06\nEpoch 600, Loss: 7.274869139373559e-05\nEpoch 700, Loss: 9.636974703522394e-08\nEpoch 800, Loss: 2.6145658593989916e-05\nEpoch 900, Loss: 4.0775460656591826e-05\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def compute_accuracy(X, Y, parameters):\n    _, _, _, _, _, A3 = forward_propagation(X, parameters)\n    predictions = np.argmax(A3, axis=0)\n    return np.mean(predictions == Y)\n\nval_accuracy = compute_accuracy(x_dev, y_dev, trained_params)\nprint(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:14:57.587692Z","iopub.execute_input":"2025-05-14T20:14:57.588055Z","iopub.status.idle":"2025-05-14T20:14:57.607784Z","shell.execute_reply.started":"2025-05-14T20:14:57.588030Z","shell.execute_reply":"2025-05-14T20:14:57.606821Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 93.20%\n","output_type":"stream"}],"execution_count":18}]}